# -*- coding: utf-8 -*-
"""CNN Model Implementation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1F4juHyqgGjhWKu5oOeCVXxg-VKN4uHPD
"""

!pip install -q opencv-python tensorflow
import os, cv2, numpy as np
from PIL import Image
import matplotlib.pyplot as plt
from google.colab import drive
import tensorflow as tf
from tensorflow.keras import layers, Model
from tensorflow.keras.callbacks import EarlyStopping

drive.mount('/content/drive', force_remount=True)
DATA_FOLDER = '/content/drive/MyDrive/LandMark Images Pre-Processed'

# Locations of landmarks from my image dataset
LOCATION_MAP = {
    "Adam's Peak": "Rathnapura, Sabaragamuwa Province, Sri Lanka",
    "Ancient City of Polonnaruwa": "Polonnaruwa, North Central Province, Sri Lanka",
    "Beruwala Light House": "Beruwala, Western Province, Sri Lanka",
    "British War Cemetery": "Kandy, Central Province, Sri Lanka",
    "Bundala National Park": "Hambantota, Southern Province, Sri Lanka",
    "Delft Island": "Jaffna, Northern Province, Sri Lanka",
    "Dowa Rock Temple": "Bandarawela, Uva Province, Sri Lanka",
    "Ganagaramaya Temple": "Colombo, Western Province, Sri Lanka",
    "Henarathgoda Botanical Gard": "Gampaha, Western Province, Sri Lanka",
    "Hortains Plain": "Nuwara Eliya, Central Province, Sri Lanka",
    "Independance Square": "Colombo, Western Province, Sri Lanka",
    "Jaya Sri Maha Bodhi": "Anuradhapura, North Central Province, Sri Lanka",
    "Lotus Tower": "Colombo, Western Province, Sri Lanka",
    "Maligawa Buddha Statue": "Kandy, Central Province, Sri Lanka",
    "Nine Arches Bridge": "Ella, Uva Province, Sri Lanka",
    "Pinnawala Elephant Orphanage": "Kegalle, Sabaragamuwa Province, Sri Lanka",
    "Sigiriya": "Matale, Central Province, Sri Lanka",
    "Sinharaja Forest": "Ratnapura, Sabaragamuwa Province, Sri Lanka",
    "Sri Dalada Maligawa": "Kandy, Central Province, Sri Lanka",
    "Star Fort": "Matara, Southern Province, Sri Lanka",
    "Turtle Hatchery": "Kosgoda, Southern Province, Sri Lanka",
    "Vavuniya Archaeological Museum": "Vavuniya, Northern Province, Sri Lanka",
    "Wilapattu National Park": "Puttalam, North Western Province, Sri Lanka",
    "Yapahuwa Rock Fortress": "Yapahuwa, North Western Province, Sri Lanka",
}

# Loading the image data
def load_images():
    X, y = [], []
    classes = sorted([d for d in os.listdir(DATA_FOLDER) if os.path.isdir(os.path.join(DATA_FOLDER, d))])

    for i, name in enumerate(classes):
        path = os.path.join(DATA_FOLDER, name)
        for file in os.listdir(path):
            if file.lower().endswith(('.jpg')):
                try:
                    img = np.array(Image.open(os.path.join(path, file)).convert('RGB'))
                    X.append(cv2.resize(img, (290, 290)) / 255.0)
                    y.append(i)
                except:
                    pass

    idx = np.random.permutation(len(X))
    split = int(0.8 * len(X))
    return np.array(X)[idx[:split]], np.array(X)[idx[split:]], np.array(y)[idx[:split]], np.array(y)[idx[split:]], classes

X_train, X_val, y_train, y_val, CLASS_NAMES = load_images()
print(f"Loaded {len(X_train)} train, {len(X_val)} val images")

"""Phase 01: Frozen base regularized to avoid overfitting and to improve the acuuracy"""

# SIMPLIFIED PHASE 1 MODEL
base = tf.keras.applications.MobileNetV2(
    input_shape=(290, 290, 3),
    include_top=False,
    weights='imagenet'
)
base.trainable = False

inputs = layers.Input(shape=(290, 290, 3))
x = base(inputs)
x = layers.GlobalAveragePooling2D()(x)
x = layers.BatchNormalization()(x)  # Add this for stability

# Correct order: Dropout -> Dense -> Output
x = layers.Dropout(0.7)(x)
x = layers.Dense(100, activation='relu')(x)
outputs = layers.Dense(len(CLASS_NAMES), activation='softmax')(x)  # ONLY ONE OUTPUT

model = Model(inputs, outputs)
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)
model.summary()

history_phase1 = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=25,
    batch_size= 21,
    callbacks=[EarlyStopping(patience=4, restore_best_weights=True, monitor='val_loss')],
    verbose=1
)

"""Visualization: Checking for overfitting"""

plt.figure(figsize=(12, 4))

# Accuracy Plot
plt.subplot(1, 2, 1)
plt.plot(history_phase1.history['accuracy'], 'b-', label='Training', linewidth=2)
plt.plot(history_phase1.history['val_accuracy'], 'r-', label='Validation', linewidth=2)
plt.title('Model Accuracy', fontsize=12, fontweight='bold')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True, alpha=0.3)
plt.ylim(0, 1)

plt.tight_layout()
plt.show()

# Print final metrics
final_train_acc = history_phase1.history['accuracy'][-1]
final_val_acc = history_phase1.history['val_accuracy'][-1]
print(f"\nFinal Training Accuracy: {final_train_acc:.2%}")
print(f"Final Validation Accuracy: {final_val_acc:.2%}")
print(f"Gap: {final_train_acc - final_val_acc:.2%} (Should be <5% to avoid overfitting)")

# This function returns the landmark name and its location
def predict(img_path):
    img = Image.open(img_path).convert('RGB')
    img_array = cv2.resize(np.array(img), (350, 350)) / 255.0
    img_array = np.expand_dims(img_array, axis=0)

    pred_idx = np.argmax(model.predict(img_array, verbose=0)[0])
    landmark = CLASS_NAMES[pred_idx]
    location = LOCATION_MAP.get(landmark, "Unknown")

    return {'name': landmark, 'place': location}

# Testing the model
result = predict('/content/drive/MyDrive/LandMark Images Processed/Delft Island/pic-3_png.rf.7abce9cfd7123d399da8bef3ac316610.jpg')
print(f"Landmark: {result['name']}")
print(f"Location: {result['place']}")