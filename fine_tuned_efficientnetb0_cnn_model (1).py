# -*- coding: utf-8 -*-
"""Fine Tuned EfficientNetB0 CNN Model

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16jLhACueuytAM6EEOKdpLYSaQ8DiokJ-
"""

import tensorflow as tf
from tensorflow.keras import layers, Model
from tensorflow.keras.callbacks import EarlyStopping
import os, cv2, numpy as np
from PIL import Image
import matplotlib.pyplot as plt
from google.colab import drive
import json

drive.mount('/content/drive', force_remount=True)
DATA_FOLDER = '/content/drive/MyDrive/LandMark Images Pre-Processed'

# Locations of landmarks from my image dataset
LOCATION_MAP = {
    "Adam's Peak": "Rathnapura, Sabaragamuwa Province, Sri Lanka",
    "Ancient City of Polonnaruwa": "Polonnaruwa, North Central Province, Sri Lanka",
    "Beruwala Light House": "Beruwala, Western Province, Sri Lanka",
    "British War Cemetery": "Kandy, Central Province, Sri Lanka",
    "Bundala National Park": "Hambantota, Southern Province, Sri Lanka",
    "Delft Island": "Jaffna, Northern Province, Sri Lanka",
    "Dowa Rock Temple": "Bandarawela, Uva Province, Sri Lanka",
    "Ganagaramaya Temple": "Colombo, Western Province, Sri Lanka",
    "Henarathgoda Botanical Gard": "Gampaha, Western Province, Sri Lanka",
    "Hortains Plain": "Nuwara Eliya, Central Province, Sri Lanka",
    "Independance Square": "Colombo, Western Province, Sri Lanka",
    "Jaya Sri Maha Bodhi": "Anuradhapura, North Central Province, Sri Lanka",
    "Lotus Tower": "Colombo, Western Province, Sri Lanka",
    "Maligawa Buddha Statue": "Kandy, Central Province, Sri Lanka",
    "Nine Arches Bridge": "Ella, Uva Province, Sri Lanka",
    "Pinnawala Elephant Orphanage": "Kegalle, Sabaragamuwa Province, Sri Lanka",
    "Sigiriya": "Matale, Central Province, Sri Lanka",
    "Sinharaja Forest": "Ratnapura, Sabaragamuwa Province, Sri Lanka",
    "Sri Dalada Maligawa": "Kandy, Central Province, Sri Lanka",
    "Star Fort": "Matara, Southern Province, Sri Lanka",
    "Turtle Hatchery": "Kosgoda, Southern Province, Sri Lanka",
    "Vavuniya Archaeological Museum": "Vavuniya, Northern Province, Sri Lanka",
    "Wilapattu National Park": "Puttalam, North Western Province, Sri Lanka",
    "Yapahuwa Rock Fortress": "Yapahuwa, North Western Province, Sri Lanka",
}

# Load images from flat structure: landmark/train/images.jpg
def load_images():

    splits = ['train', 'test', 'valid']
    X_train, y_train = [], []
    X_val, y_val = [], []
    X_test, y_test = [], []

    # Get landmark names (folders containing train/test/valid)
    classes = []
    for item in os.listdir(DATA_FOLDER):
        item_path = os.path.join(DATA_FOLDER, item)
        if os.path.isdir(item_path):
            subfolders = os.listdir(item_path)
            if all(split in subfolders for split in splits):
                classes.append(item)

    classes = sorted(classes)
    print(f"üìÅ Found {len(classes)} landmarks: {classes}")

    # Create class to index mapping
    class_to_idx = {name: i for i, name in enumerate(classes)}

    # Load images from each split
    for landmark in classes:
        for split in splits:
            # Direct path: landmark/train/ (no inner folder)
            source_path = os.path.join(DATA_FOLDER, landmark, split)

            if not os.path.exists(source_path):
                print(f"‚ö†Ô∏è Missing: {landmark}/{split}")
                continue

            # Get images directly from split folder
            images = [f for f in os.listdir(source_path)
                     if f.lower().endswith(('.jpg', '.jpeg', '.png', '.webp'))]

            print(f"üìÇ {landmark}/{split}: {len(images)} images")

            for img_name in images:
                try:
                    img_path = os.path.join(source_path, img_name)
                    img = np.array(Image.open(img_path).convert('RGB'))
                    img_resized = cv2.resize(img, (290, 290)) / 255.0

                    # Add to appropriate list
                    if split == 'train':
                        X_train.append(img_resized)
                        y_train.append(class_to_idx[landmark])
                    elif split == 'valid':
                        X_val.append(img_resized)
                        y_val.append(class_to_idx[landmark])
                    elif split == 'test':
                        X_test.append(img_resized)
                        y_test.append(class_to_idx[landmark])

                except Exception as e:
                    print(f"‚ö†Ô∏è Failed {img_name}: {e}")

    # Convert to numpy arrays
    X_train = np.array(X_train)
    y_train = np.array(y_train)
    X_val = np.array(X_val)
    y_val = np.array(y_val)
    X_test = np.array(X_test)
    y_test = np.array(y_test)

    print(f"\n‚úÖ Loaded:")
    print(f"   Train: {len(X_train)} images")
    print(f"   Val:   {len(X_val)} images")
    print(f"   Test:  {len(X_test)} images")

    return X_train, X_val, X_test, y_train, y_val, y_test, classes

X_train, X_val, X_test, y_train, y_val, y_test, CLASS_NAMES = load_images()

"""Unfreeze model and Finetune it"""

# Load base model
base = tf.keras.applications.EfficientNetB0(
    input_shape=(290, 290, 3),
    include_top=False,
    weights='imagenet'
)

# Unfreeze top 4 layers for fine-tuning
base.trainable = True
for layer in base.layers[:-4]:
    layer.trainable = False

print(f"Trainable: {sum(1 for l in base.layers if l.trainable)}/{len(base.layers)}")

# Build model
inputs = layers.Input(shape=(290, 290, 3))
x = layers.Lambda(lambda x: x * 255.0)(inputs)

x = base(x)
x = layers.GlobalAveragePooling2D()(x)
x = layers.BatchNormalization()(x)

x = layers.Dropout(0.5)(x)
x = layers.Dense(150, activation='relu')(x)
x = layers.Dropout(0.45)(x)
outputs = layers.Dense(len(CLASS_NAMES), activation='softmax')(x)

model = Model(inputs, outputs)

# Compile with Low learning rate
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002),
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

model.summary()

history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=31,
    batch_size=32,
    callbacks=[EarlyStopping(patience=15, restore_best_weights=True, monitor='val_accuracy', mode='max')],
    verbose=1
)

# Accuracy Plot
plt.figure(figsize=(16, 5))

plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], 'b-', label='Training', linewidth=2)
plt.plot(history.history['val_accuracy'], 'r-', label='Validation', linewidth=2)
plt.title('Model Accuracy', fontsize=12, fontweight='bold')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True, alpha=0.3)
plt.ylim(0, 1)

plt.tight_layout()
plt.show()

# Print final metrics
final_train_acc = history.history['accuracy'][-1]
final_val_acc = history.history['val_accuracy'][-1]
print(f"\nFinal Training Accuracy: {final_train_acc:.2%}")
print(f"Final Validation Accuracy: {final_val_acc:.2%}")
print(f"Gap: {final_train_acc - final_val_acc:.2%} ")

print("The model is no longer overfitting.")

# This function returns the landmark name and its location
def predict(img_path):
    img = Image.open(img_path).convert('RGB')
    img_array = cv2.resize(np.array(img), (290, 290)) / 255.0
    img_array = np.expand_dims(img_array, axis=0)

    pred_idx = np.argmax(model.predict(img_array, verbose=0)[0])
    landmark = CLASS_NAMES[pred_idx]
    location = LOCATION_MAP.get(landmark, "Unknown")

    return {'name': landmark, 'place': location}

# Testing the model
result = predict('/content/drive/MyDrive/LandMark Images Pre-Processed/Delft Island/train/pic-5_png.rf.d35918beaa463d759741d983603d636f.jpg')
print(f"Landmark: {result['name']}")
print(f"Location: {result['place']}")

model.save('/content/drive/MyDrive/FineTuned01-EfficientNetB0_CNN_Model.keras')
print("‚úÖ Model saved")

# Save class names
with open('/content/drive/MyDrive/class_names.json', 'w') as f:
    json.dump(CLASS_NAMES, f)
print("‚úÖ Class names saved")